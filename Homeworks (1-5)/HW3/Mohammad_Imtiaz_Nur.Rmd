---
title: "HW3"
author: "Mohammad Imtiaz Nur"
date: "4/2/2021"
output: pdf_document
---

# TASK 1


```{r task1}
data1 <- data.frame(supplier = rep(c('supplier1','supplier2','supplier3', 'supplier4'),each=4),
                    ts=c( c(19, 21, 19, 29), c(80, 71, 63, 56), 
                          c(47, 26, 25, 35), c(90, 49, 83, 78)))


supplierFactor <- factor(data1$supplier)
analysis <- aov(data1$ts ~ supplierFactor)
summary(analysis)

par(mfrow=c(1,1))
boxplot(data1$ts~supplierFactor,xlab="supplier",
        ylab="Tensile Strength", main="Supplier vs Tensile Strength")
means <- tapply(data1$ts, supplierFactor, mean)
points(means,pch =8 ,col="red")
```

1(a): As the p-value is much less than the significance level 0.05, we can conclude that there are significant differences between the groups highlighted with “*" in the model summary.

```{r 1b}
TukeyHSD(analysis)
```


# TASK 2


```{r task2}
branch = c("branch1","branch1","branch1","branch1","branch2","branch2","branch2","branch3","branch3","branch3")
sl = c(15, 20, 19, 14, 11, 15, 11, 18, 19, 23)
data2 <- data.frame(branch, sl)

analysis <- aov(data2$sl ~ branch)
summary(analysis)
```


2(a): As the p-value is less than the significance level 0.05, we can conclude that there are significant differences between the groups.


```{r 2b_duncan}
library("DescTools")
duncan_test <- PostHocTest(analysis, method = "duncan")
duncan_test
```

2(b): From the Duncan-test, we can see branch3-branch2 differ significantly at 0.05 confidence level.



# Task 3

(a) The negative slope implies that, there is a negative correlation between the time spent in reading the description and the response time. Hence, with the increase of time spent in reading the description, the response time decreases.


(b)

Calculating the confidence interval: 

ME = Standard Error * Critical Value


where,
ME = Maximum Error; SE = Standard Error


and 


Critical value is considered for (1 - alpha/ 2) and degree of freedom 18; Or the region without the tails
SE = beta/t_statistics; Considering beta_0 is 0. 

```{r task3}
DF <- 18
beta <- -0.03
t_stat <- -2.11
y.est <- 0 + (-0.03)*20 
SE <- beta/t_stat
alpha <- 0.05
p_star <- 1 - alpha/2
critical_value <- qt(p_star,18)
ME <- SE * critical_value

print("Deviation From Beta")
ME

print("Lower interval for Beta")
beta-ME

print("Upper interval for Beta")
beta+ME


y.est <- beta*20

print("Lower interval for 20")
y.est-ME

print("Prediction value for 20")
y.est

print("Upper interval for 20")
y.est+ME
```

#(c)

r^2 = t_stat ^ 2 / t_stat ^ 2 + Degree of freedom
```{r 3c}
r_squared = t_stat*t_stat/(t_stat*t_stat+18)
r_squared
```

The r_squared value is 0.1983 which is only 20 percent variation of the data that is captured by our model.


# Task 4

```{r tast4_stress}
percent_binder = c(5.3, 5.3, 5.3, 6.0, 7.8, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 10.0, 12.0, 12.0, 12.0, 12.0, 14.0)
loading_rate = c(0.02, 0.02, 0.02, 2.00, 0.20, 2.0, 2.0, 2.0, 2.0, 0.02, 0.02, 0.02, 0.02, 2.0, 0.02, 0.02, 0.02, 0.02, 0.02)
ambient_temperature = c(77, 32, 0, 77, 77, 104, 77, 32, 0, 104, 77, 32, 0, 77, 77, 32, 0, 104, 77)
stress  = c(42, 481, 543, 609, 444, 194, 593, 977, 872, 35, 96, 663, 702, 518, 40, 627, 683, 22, 35)
strain  = c(3.20, 0.73, 0.16, 1.44, 3.68, 3.11, 3.07, 0.19, 0.00, 5.86, 5.97, 0.29, 0.04, 2.72, 7.35, 1.17, 0.14, 15.00, 11.80)

df<- data.frame(percent_binder, loading_rate, ambient_temperature, stress, strain)

stress_model <- lm(stress~percent_binder+loading_rate+ambient_temperature, data = df)
summary(stress_model)
par(mfrow=c(2, 2))
plot(stress_model)
```


In the "Residual vs Fitted" plot, there is non-linearity in the data, as the red line has irregular curve and the residual samples are not equally distributed two sides of the red line.


In the "Normal Q-Q" plot, residuals deviation from normality throughout the sample.


In the "Scale-Location" plot, there is an irragular trend as the red line is not flat which implies the errors are non-constant and proves the presence of heteroscedasticity. 


In the "Residuals vs Leverage" plot, we can see most points are clustered on a high leverage point. Though there are some outliers, the outliers are not that influential. 

Here, H0 =  Model with no independent variables fits the data as well as our model,
H1 = Model fits the data better than the intercept-only model.

As the p-value is less than 0.05, we can reject the null hypothesis. Our regression model fits the data better than the model with no independent variables.

From the t- statistics we can see loading_rate and ambient_temperature is significant for the stress, but percent_binder is non-significant.


```{r task4_strain, echo=FALSE}
strain_model <- lm(strain~percent_binder+loading_rate+ambient_temperature, data = df)
summary(strain_model)
par(mfrow=c(2, 2))
plot(strain_model)
```



In the "Residual vs Fitted" plot, there is non-linearity in the data, as the red line has irregular curve and the residual samples are not equally distributed two sides of the red line.


In the "Normal Q-Q" plot, residuals deviation from normality throughout the sample.


In the "Scale-Location" plot, there is an irragular trend as the red line is not flat which implies the errors are non-constant and proves the presence of heteroscedasticity. 


In the "Residuals vs Leverage" plot, we can see most points are clustered on a high leverage point. Though there are some outliers, the outliers are not that influential. 

Here, H0 =  Model with no independent variables fits the data as well as our model,
H1 = Model fits the data better than the intercept-only model.

As the p-value is less than 0.05, we can reject the null hypothesis. Our regression model fits the data better than the model with no independent variables.


From the t- statistics we can see all three variables are significant for the strain.


# Task 5

Lets assume our first model where m = 2 is the restricted version of our second model. So our unrestricted model has five variables and in the restricted version we have restricted three burnout variables. Apparently our unrestricted model has better R squared value, so we can say it predicts better. Now, to do the significance test, I have calculated F statistics for the Restricted vs Unrestricted model.  The equation is:
 
F =  ((URSS - RRSS)/(1-URSS))*((N-K)/q) 

Where,

URSS = Unrestricted Residual Sum of Squares

RRSS = Restricted Residual Sum of Squares 

N = Sample size

K = The number of parameters estimated in the unrestricted model

q = The number of restrictions imposed

```{r task5}

URSS = 0.34
RRSS = 0.05
N = 220
K = 5
q = 3

F = ((URSS - RRSS)/(1-URSS))*((N-K)/q)

F

p = 0.05

# number of x variables in the model
df1 = 2

# sample size – number of x variables – 1 
df2 = N - df1 - 1

# Critical value from table for p, df1 and df2
critical_value = 3.307
```

Here, we found F value=31.4899. But for our two variables from the model and alpha 0.05, our F value need to be greater than critical value (3.307). So, we can reject the null hypothesis, that is the regression component of burnout variables are zero. So, the alternate hypothesis is true, that is, they are not zero and we can say at least one of the burnout scores is related to psychosomatic complaints.
